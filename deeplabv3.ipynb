{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikrp\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vikrp\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.segmentation as models\n",
    "\n",
    "class DeepLabV3Binary(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(DeepLabV3Binary, self).__init__()\n",
    "        \n",
    "        # Load pre-trained DeepLabV3\n",
    "        self.model = models.deeplabv3_resnet101(pretrained=pretrained)\n",
    "        \n",
    "        # Modify the classifier for binary segmentation (1 output channel)\n",
    "        in_features = self.model.classifier[4].in_channels  # Get input channels of last layer\n",
    "        self.model.classifier[4] = nn.Conv2d(in_features, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)['out']  # Return only segmentation mask\n",
    "\n",
    "# Initialize model and move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "deeplab_model = DeepLabV3Binary().to(device)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(deeplab_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, mask_transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.classes = [\"Mask\", \"No Mask\"]\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                if os.path.isfile(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_paths.append(img_path)  # Assuming masks are stored in same location\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]  # Replace with actual mask path if needed\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert to grayscale\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Define transforms for images and masks\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = MaskDataset(root_dir=\"dataset\", transform=image_transform, mask_transform=mask_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.4720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.4677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    deeplab_model.train()\n",
    "    epoch_loss = 0\n",
    "    loop = tqdm(train_loader, leave=False)\n",
    "\n",
    "    for images, masks in loop:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = deeplab_model(images)\n",
    "\n",
    "        # Ensure masks have the same shape as the output\n",
    "        #masks = masks.squeeze(1)  # Add channel dim (batch, 1, H, W)\n",
    "        \n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "def predict_mask(image_path, model):\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    mask = torch.sigmoid(output).squeeze().cpu().numpy()\n",
    "    mask = (mask > 0.5).astype(np.uint8)  # Convert to binary mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Test with an image\n",
    "test_image = \"samplex.jpeg\"\n",
    "predicted_mask = predict_mask(test_image, deeplab_model)\n",
    "\n",
    "plt.imshow(predicted_mask, cmap='gray')\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained DeepLabV3 model with a ResNet backbone\n",
    "deeplab_model = models.segmentation.deeplabv3_resnet101(pretrained=True).to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "deeplab_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "# Define the transform for preprocessing the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize images to 256x256\n",
    "    transforms.ToTensor(),          # Convert images to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "# Assuming the dataset is in 'dataset/val_data' with 'Mask' and 'No Mask' folders\n",
    "val_dataset = datasets.ImageFolder(root='dataset', transform=transform)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_metrics(model, dataloader, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate metrics for semantic segmentation with continuous-valued masks.\n",
    "    \n",
    "    Args:\n",
    "        model: The segmentation model\n",
    "        dataloader: DataLoader containing images and masks\n",
    "        device: torch device to use\n",
    "        threshold: Threshold for binarizing both predictions and masks (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (accuracy, precision, recall, f1, iou)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, leave=False):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs['out']\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            # For binary segmentation, take channel 1 (foreground)\n",
    "            # or sum across all channels except background\n",
    "            preds = probs[:, 1:, :, :].sum(dim=1, keepdim=True)\n",
    "            \n",
    "            # Ensure predictions and masks are in range [0, 1]\n",
    "            preds = torch.clamp(preds, 0, 1)\n",
    "            masks = torch.clamp(masks, 0, 1)\n",
    "            \n",
    "            # Print shapes and value ranges for debugging\n",
    "            print(f\"\\nDebug - Batch Statistics:\")\n",
    "            print(f\"Predictions shape: {preds.shape}, range: [{preds.min():.4f}, {preds.max():.4f}]\")\n",
    "            print(f\"Masks shape: {masks.shape}, range: [{masks.min():.4f}, {masks.max():.4f}]\")\n",
    "            \n",
    "            # Binarize both predictions and masks using threshold\n",
    "            preds_binary = (preds > threshold).float()\n",
    "            masks_binary = (masks > threshold).float()\n",
    "            \n",
    "            # Convert to numpy and flatten\n",
    "            preds_flat = preds_binary.cpu().numpy().reshape(-1)\n",
    "            masks_flat = masks_binary.cpu().numpy().reshape(-1)\n",
    "            \n",
    "            all_preds.append(preds_flat)\n",
    "            all_labels.append(masks_flat)\n",
    "    \n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # Print final statistics\n",
    "    print(\"\\nFinal Statistics:\")\n",
    "    print(f\"Total pixels processed: {len(all_preds)}\")\n",
    "    print(f\"Positive pixels in predictions: {np.sum(all_preds == 1)}\")\n",
    "    print(f\"Positive pixels in masks: {np.sum(all_labels == 1)}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    # Calculate IoU (Intersection over Union)\n",
    "    intersection = np.logical_and(all_preds, all_labels).sum()\n",
    "    union = np.logical_or(all_preds, all_labels).sum()\n",
    "    iou = intersection / union if union != 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1, iou\n",
    "\n",
    "# Example usage:\n",
    "try:\n",
    "    accuracy, precision, recall, f1, iou = calculate_metrics(\n",
    "        model=deeplab_model,\n",
    "        dataloader=train_loader,\n",
    "        device=device,\n",
    "        threshold=0.5  # Adjust this threshold based on your needs\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEvaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    \n",
    "    # Get a sample batch for debugging\n",
    "    images, masks = next(iter(train_loader))\n",
    "    print(f\"\\nSample batch information:\")\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Masks shape: {masks.shape}\")\n",
    "    print(f\"Mask value range: [{masks.min():.4f}, {masks.max():.4f}]\")\n",
    "    print(f\"Unique mask values: {torch.unique(masks)[:10]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
